想法起点 vit 浅 中 深三层特征融合

如何动态选择 
对每一个图片输入，根据下游任务，选择不同的数据增强变化（比如说 缩放 颜色抖动），生成不同的增强图片。
将两个（or多个）不同增强后的图片输入到vit中，在每个层得到不同的特征表示，计算两个特征表示的相似度，作为该层的稳定性得分，从而（24层的稳定性得分）生成一个层稳定性曲线图。
为了避免总是选择最深的层，可以通过相邻层的稳定性得分提升量作为信息增益，反应曲线局部斜率，在每一个层级（浅层1-B 中层B+1-M 深层M+1-L），然后根据信息增益的均值和标准差来定一个阈值，当信息增益小于这个阈值时，就认为该层的上一层是平台起点，然后选择平台起点作为该池的代表层。（问题1 如果信息增益在平台后又突然增大呢 会不会陷入局部最优 问题2 根据信息增益真的能够代表特征表示的好坏吗）

baseline对比
1.单层输出
2. 3层 8层 23层融合
3. 所有层融合
3. 动态门控网络融合（生成统一权重向量）


---

### **方法论：结构化约束下的动态视觉层融合**


#### **3.1. 信号生成：层级稳定性分析 (Signal Generation: Layer-wise Stability Analysis)**

借鉴自监督学习和不确定性量化的核心思想，将一个层级特征的**“确定性”**定义为其对输入数据微小扰动的**“稳定性”**。一个对扰动不敏感、输出稳定的层级，被认为是“确定性”高的。

**步骤 1：任务自适应的视图生成 (Task-Adaptive View Generation)**
对于每一张输入图像 $I$，应用两种根据下游任务特点精心选择的、不同的数据增强变换 $T_1$ 和 $T_2$，生成两个语义上等价但像素上不同的视图：$I_{v1} = T_1(I)$ 和 $I_{v2} = T_2(I)$。例如，对于需要保持几何结构的科学图表，采用轻微的缩放和颜色抖动；对于通用图像，则采用更激进的随机裁剪和翻转。

**步骤 2：多层级特征提取 (Multi-Level Feature Extraction)**
将这两个视图并行地输入一个预训练好的、权重冻结的ViT编码器。对于ViT的所有 $L$ 个层级（例如 $L=24$），提取出每一层的patch token输出，得到两组特征序列：
$\{F^1_1, F^1_2, ..., F^1_L\}$ 和 $\{F^2_1, F^2_2, ..., F^2_L\}$
其中 $F^k_l \in \mathbb{R}^{N \times D}$ 是视图 $k$ 在第 $l$ 层的特征，$N$ 是patch数量，$D$ 是特征维度。

**步骤 3：稳定性信号量化 (Stability Signal Quantification)**
在每一个层级 $l$，计算两个视图输出特征之间的平均余弦相似度，作为该层级的**稳定性得分 $S_l$**：
$S_l = \text{mean}(\text{CosineSimilarity}(F^1_l, F^2_l))$
这会为每张图片生成一条从浅到深的**“层级稳定性曲线” $S = [S_1, S_2, ..., S_L]$**。根据深度网络的层次化抽象特性，这条曲线通常呈现单调递增的趋势。

#### **3.2. 决策制定：带约束的信息增益最大化 (Decision Making: Constrained Information Gain Maximization)**

简单地选择最稳定（$S_l$ 最高）的层会导致永远偏爱深层，而这些深层特征往往存在冗余。的目标是选择那些**“性价比”最高**的层，即**模型“认知状态”发生关键跃迁的转折点**。

**步骤 1：信息增益计算 (Information Gain Calculation)**
计算相邻层级之间稳定性的**提升量 $\Delta S_l$**，作为第 $l$ 层带来的**“信息增益”**：
$\Delta S_l = S_l - S_{l-1}$ (其中 $S_0=0$)
这个 $\Delta S$ 序列反映了稳定性曲线的局部斜率，衡量了每一层带来的“新确定性”。

**步骤 2：结构化池划分 (Structural Pool Partitioning)**
受到[Lin et al.]的启发，为了确保最终特征的全面性，将所有 $L$ 个层级预先划分为三个功能上不同的**结构化池**：
*   **浅层池 (Beginning Pool)**: $P_B = \{1, ..., B\}$
*   **中层池 (Middle Pool)**: $P_M = \{B+1, ..., M\}$
*   **深层池 (Ending Pool)**: $P_E = \{M+1, ..., L\}$

**步骤 3：动态代表选择算法 (Dynamic Representative Selection Algorithm)**
的核心决策算法将在**每个池内部独立运行**，为每个池挑选出一个最佳代表层：
对于每个池 $P \in \{P_B, P_M, P_E\}$：
1.  **寻找平台起点**: 从池的起始层开始，逐层检查信息增益 $\Delta S_l$。寻找第一个满足 $\Delta S_l < \varepsilon$ 的层级。这个**“信息增益阈值” `ε`** 是动态计算的，例如，可以设为当前池内所有`ΔS`值的**均值减去一个小的标准差倍数 (`μ_ΔS - α * σ_ΔS`)**。这个点被认为是该功能阶段的“认知饱和点”。
2.  **选择最佳代表**: 将这个“平台起点”层作为该池的**最佳代表层 $l^*$**。如果池内所有层的`ΔS`都大于`ε`，则选择池内稳定性 $S_l$ 最高的层作为代表。

通过这个算法，对于每张图片，都会动态地得到一个包含三个层级索引的组合，例如 `{l^*_B, l^*_M, l^*_E}`。

#### **3.3. 最终融合 (Final Fusion)**

遵循[Lin et al.]验证的最佳实践，采用**外部直接融合**策略：
1.  **特征获取**: 从ViT中获取上一步动态选择出的三个代表层的patch token特征：$F_{l^*_B}, F_{l^*_M}, F_{l^*_E}$。
2.  **直接相加**: 将这三个特征张量进行**逐元素相加**，得到最终的融合特征 $F_{fused}$：
    $F_{fused} = F_{l^*_B} + F_{l^*_M} + F_{l^*_E}$
3.  **送入下游**: 将这个融合后的、信息丰富且非冗余的视觉特征序列 $F_{fused}$ 送入后续的LLM进行处理。
