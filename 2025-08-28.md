Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution
arXiv:2307.06304
把图像拆成任意大小的 patch 后直接 pack 成一个长序列，不拉伸

---
## 结构的改变

#### 1) Masked self-attention & masked pooling  （训练方法）
- 将多张不同图片的 patch 拼接成一个长序列，在 self-attention 里加 mask，只允许同一张图片内的 patch 互相看到。  
- pooling 时也只看同一张图片的 patch，输出这张图的向量。

#### 2) 位置编码的改造  
- Pix2struct：直接学一个 [maxLen, maxLen] 的 2-D 绝对表，测试时按 (x,y) 直接查表，但训练时必须见过所有 (x,y) 组合。  

NaViT 提出两种更灵活的方案：  
- **factorized absolute**：x、y 各学一套 φx、φy，最后相加；坐标范围 [0, maxLen]。  
- **fractional**：坐标归一化到 [0,1]，编码器只关心“相对位置”，与具体像素尺寸解耦；但长宽比信息只剩 patch 数目隐含。  
- 可选实现：简单可学习向量、正弦曲线、NeRF 的 Fourier 特征。

---

## 训练的改变

#### 1) Continuous Token Dropping  
-可以自由设置drop的比例，动态变化

#### 2) Resolution Sampling  
- 可以混合分辨率采样，训练时同一张图片每次被随机放大或缩小，但长宽比不变，于是同一个 batch 里既有小图也有大图
---

### 计算效率的改善

#### 1) 自注意力开销  
-当模型Transformer 里每个 token（patch）被映射成的向量的长度变大，因为packaging导致的attention计算量占比反而减小

#### 2) Padding 问题  
- 通过padding将packaging后的长序列的token补充到固定长度

#### 3) 对比学习  
- 把 N 个向量（一个图片一个向量）切成若干chunk，块先在本地设备算局部 softmax；再把各块的信息汇总，做一次全局归约，得到跟原先整个向量softmax一样的结果；计算/显存峰值只跟 chunk 大小成比例，可以在序列中塞入更多张图片


---

