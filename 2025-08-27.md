DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding

arXiv:2412.10302
https://github.com/deepseek-ai/DeepSeek-VL2

给定任意图，先算长宽比→挑一个 m×n≤9 的 384 倍率分辨率→切成 m×n+1 张 384² tile→SigLIP 提特征→pixel-shuffle+特殊 token→送进大模型

--------------------------  

1. 候选分辨率集合  
   定义候选分辨率集合  
   CR = {(m·384, n·384) | m,n∈ℕ, 1≤m,n, m·n≤9}  
   共 9 组：(1×1, 1×2, 1×3, 1×4, 1×5, 1×6, 1×7, 1×8, 1×9) 及其转置。  
   最大物理尺寸 = 9×384 = 3456 px。  
2. 选分辨率（最小填充）  
   对输入图 (H,W)  
   1. 长边先缩放到目标尺寸，短边按比例缩放 → 得中间图。  
   2. 计算把中间图 pad 到 (m·384, n·384) 所需填充面积。  
   3. 选填充最小的 (mᵢ·384, nᵢ·384)。  
3. 切片  
   • 把缩放后的图切成 mᵢ×nᵢ 个 384×384 **局部 tile**。  
   • 额外保留一张 384×384 **全局缩略图 tile**（整张图再缩一次）。  
   • 共 1+mᵢ·nᵢ 个 tile。  

4. 视觉编码  
   • 每个 tile 送 SigLIP-SO400M-384 → 27×27×1152 特征（729 tokens）。  
   • 若一次处理图数>2，则退化成“整张图直接缩到 384×384”以省显存。  

5. Token 压缩与拼接  
   • 2×2 pixel-shuffle：27×27 → 14×14 = 196 tokens。  
   • 特殊 token：  
     – 全局缩略图：每行末尾加 `<tile_newline>`，共 14 行 → 14×15 = 210 tokens。  
     – 局部 tile：在 (mᵢ·14, nᵢ·14) 的 2-D grid 中，每行末尾加 `<tile_newline>`；整张局部 tile 末尾再加 `<view_separator>` 区分全局/局部。  
   • 最终视觉序列长度：  
     210 (global) + 1 (sep) + mᵢ·14×(nᵢ·14+1) (locals)。  

--------------------------  
